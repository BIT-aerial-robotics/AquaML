"""AquaML Coordinator

This module provides the main coordinator for the AquaML framework.
"""

from typing import Dict, Any, Optional
from loguru import logger
import torch
from torch.nn import Module

from .device_info import GPUInfo, detect_gpu_devices, get_optimal_device
from .exceptions import AquaMLException
from .tensor_tool import TensorTool
from .managers import (
    ModelManager,
    EnvironmentManager,
    AgentManager,
    DataUnitManager,
    FileSystemManager,
    CommunicatorManager,
    DataManager,
    RunnerManager,
)

# Global device variables
global_device = None
available_devices = []


class AquaMLCoordinator:
    """Main coordinator for AquaML framework

    This class serves as the central hub for managing components,
    configuration, and device management in the AquaML framework.
    """

    _instance = None
    _initialized = False

    def __new__(cls, *args, **kwargs):
        """Singleton pattern implementation"""
        if not cls._instance:
            # Welcome message
            print(
                "\033[1;34mðŸŒŠ Welcome to AquaML - Advanced Machine Learning Framework! ðŸŒŠ\033[0m"
            )
            cls._instance = super().__new__(cls)
        return cls._instance

    def __init__(self):
        """Initialize the coordinator"""
        if self._initialized:
            return

        # Initialize all specialized managers
        self.model_manager = ModelManager()
        self.environment_manager = EnvironmentManager()
        self.agent_manager = AgentManager()
        self.data_unit_manager = DataUnitManager()
        self.file_system_manager = FileSystemManager()
        self.communicator_manager = CommunicatorManager()
        self.data_manager = DataManager()
        self.runner_manager = RunnerManager()

        # Plugin and config managers (optional)
        self._plugin_manager = None
        self._config_manager = None

        self._initialized = True

        self.tensor_tool = TensorTool()
        logger.info("AquaML Coordinator initialized")

    def initialize(self, config: Optional[Dict[str, Any]] = None) -> None:
        """Initialize the coordinator with configuration

        Args:
            config: Configuration dictionary
        """
        try:
            # Initialize device management
            self._initialize_device_management(config)

            # Initialize plugin manager
            self._initialize_plugin_manager()

            # Initialize configuration manager
            self._initialize_config_manager(config)

            # Load plugins if configured
            if config and "plugins" in config:
                self._load_plugins(config["plugins"])

            logger.info("AquaML Coordinator fully initialized")

        except Exception as e:
            logger.error(f"Failed to initialize AquaML Coordinator: {e}")
            raise AquaMLException(f"Coordinator initialization failed: {e}")

    def _initialize_device_management(
        self, config: Optional[Dict[str, Any]] = None
    ) -> None:
        """Initialize device management system

        Args:
            config: Configuration dictionary that may contain device specifications
        """
        global global_device, available_devices

        # Detect available GPU devices
        available_devices = detect_gpu_devices()

        # Set device based on config or auto-detection
        user_device = None
        if config and "device" in config:
            user_device = config["device"]

        global_device = self._select_device(user_device)
        logger.info(f"Selected device: {global_device}")
        logger.info(f"Available GPU devices: {len(available_devices)}")

    def _select_device(self, user_device: Optional[str] = None) -> str:
        """Select appropriate device based on user preference and availability

        Args:
            user_device: User-specified device (e.g., 'cuda:0', 'cpu')

        Returns:
            Selected device string
        """
        global available_devices

        # If user specified a device, validate and use it
        if user_device:
            if user_device == "cpu":
                logger.info("Using user-specified CPU device")
                return "cpu"

            # Check if user specified GPU exists
            for gpu in available_devices:
                if gpu.device_id == user_device:
                    logger.info(f"Using user-specified device: {user_device}")
                    return user_device

            logger.warning(
                f"User-specified device '{user_device}' not available. Using auto-selection."
            )

        # Auto-selection: prefer GPU 0 if available
        if available_devices:
            optimal_device = get_optimal_device(available_devices)
            logger.info(f"Auto-selecting device: {optimal_device}")
            return optimal_device
        else:
            logger.info("No GPU available, using CPU")
            return "cpu"

    def get_device(self) -> str:
        """Get current device

        Returns:
            Current device string
        """
        global global_device
        if global_device is None:
            global_device = "cpu"
        return global_device

    def get_torch_device(self):
        """Get PyTorch device object

        Returns:
            torch.device object
        """
        return torch.device(self.get_device())

    def set_device(self, device: str) -> bool:
        """Set device for computation

        Args:
            device: Device string (e.g., 'cuda:0', 'cpu')

        Returns:
            True if device was set successfully, False otherwise
        """
        global global_device, available_devices

        if device == "cpu":
            global_device = "cpu"
            logger.info("Device set to: cpu")
            return True

        # Check if GPU device exists
        for gpu in available_devices:
            if gpu.device_id == device:
                global_device = device
                logger.info(f"Device set to: {device}")
                return True

        logger.error(
            f"Device '{device}' not available. Available devices: {self.get_available_devices()}"
        )
        return False

    def get_available_devices(self) -> list:
        """Get list of available devices

        Returns:
            List of available device strings
        """
        global available_devices
        devices = ["cpu"]
        devices.extend([gpu.device_id for gpu in available_devices])
        return devices

    def validate_device(self, device: str) -> bool:
        """Validate device string

        Args:
            device: Device string (e.g., 'cuda:0', 'cpu')

        Returns:
            bool: True if device is valid, False otherwise
        """
        global available_devices

        # CPU is always available
        if device == "cpu":
            return True

        # Check if the device is in the list of available GPU devices
        for gpu in available_devices:
            if gpu.device_id == device:
                return True

        logger.error(
            f"Device '{device}' not available. Available devices: {self.get_available_devices()}"
        )
        return False

    def is_gpu_available(self) -> bool:
        """Check if GPU is available

        Returns:
            True if GPU is available, False otherwise
        """
        global available_devices
        return len(available_devices) > 0

    def get_device_info(self) -> Dict[str, Any]:
        """Get comprehensive device information

        Returns:
            Dictionary containing device information
        """
        global global_device, available_devices

        info = {
            "current_device": self.get_device(),
            "available_devices": self.get_available_devices(),
            "gpu_available": self.is_gpu_available(),
            "gpu_count": len(available_devices),
        }

        if available_devices:
            info["gpu_details"] = [gpu.to_dict() for gpu in available_devices]

        return info

    def _initialize_plugin_manager(self) -> None:
        """Initialize plugin manager"""
        try:
            from ..plugins.manager import PluginManager

            self._plugin_manager = PluginManager()
            logger.debug("Plugin manager initialized")
        except ImportError:
            logger.warning("Plugin manager not available")

    def _initialize_config_manager(self, config: Optional[Dict[str, Any]]) -> None:
        """Initialize configuration manager"""
        try:
            from ..config.manager import ConfigManager

            self._config_manager = ConfigManager()
            if config:
                self._config_manager.load_config(config)
            logger.debug("Config manager initialized")
        except ImportError:
            logger.warning("Config manager not available")

    def _load_plugins(self, plugin_configs: Dict[str, Any]) -> None:
        """Load plugins from configuration

        Args:
            plugin_configs: Plugin configuration dictionary
        """
        if not self._plugin_manager:
            logger.warning("Plugin manager not available, skipping plugin loading")
            return

        for plugin_name, plugin_config in plugin_configs.items():
            try:
                self._plugin_manager.load_plugin(
                    plugin_config.get("path", ""), plugin_config.get("config", {})
                )
                logger.info(f"Loaded plugin: {plugin_name}")
            except Exception as e:
                logger.error(f"Failed to load plugin {plugin_name}: {e}")

        # ==================== Model Registration ====================

    def registerModel(self, model: Module, model_name: str):
        """å°†æ¨¡åž‹æ³¨å†Œåˆ°æ¨¡åž‹å­—å…¸ä¸­

        Args:
            model: æ¨¡åž‹å®žä¾‹
            model_name: æ¨¡åž‹åç§°
        """
        self.model_manager.register_model(model, model_name)

    def getModel(self, model_name: str) -> Dict[str, Any]:
        """èŽ·å–æ¨¡åž‹å®žä¾‹å’Œå½“å‰çŠ¶æ€

        Args:
            model_name: æ¨¡åž‹åç§°

        Returns:
            æ¨¡åž‹å­—å…¸ï¼ŒåŒ…å« 'model' å’Œ 'status' é”®
        """
        return self.model_manager.get_model(model_name)

    # ==================== Environment Registration ====================
        def registerEnv(self, env_cls):
        """æ³¨å†ŒçŽ¯å¢ƒå®žä¾‹ï¼Œæ–¹ä¾¿é›†ä¸­ç®¡ç†
        
        Args:
            env_cls: çŽ¯å¢ƒç±»
        """
        return self.environment_manager.register_env(env_cls)

    def getEnv(self):
        """èŽ·å–çŽ¯å¢ƒå®žä¾‹
        
        Returns:
            çŽ¯å¢ƒå®žä¾‹
        """
        return self.environment_manager.get_env()

    # ==================== Agent Registration ====================
        def registerAgent(self, agent_cls):
        """æ³¨å†Œæ™ºèƒ½ä½“å®žä¾‹ï¼Œæ–¹ä¾¿é›†ä¸­ç®¡ç†
        
        Args:
            agent_cls: æ™ºèƒ½ä½“ç±»
        """
        return self.agent_manager.register_agent(agent_cls)

    def getAgent(self):
        """èŽ·å–æ™ºèƒ½ä½“å®žä¾‹
        
        Returns:
            æ™ºèƒ½ä½“å®žä¾‹
        """
        return self.agent_manager.get_agent()

    # ==================== Data Unit Registration ====================
        def registerDataUnit(self, data_unit_cls):
        """æ³¨å†Œæ•°æ®å•å…ƒå®žä¾‹ï¼Œæ–¹ä¾¿é›†ä¸­ç®¡ç†
        
        Args:
            data_unit_cls: æ•°æ®å•å…ƒç±»
        """
        return self.data_unit_manager.register_data_unit(data_unit_cls)

    def getDataUnit(self, unit_name: str):
        """èŽ·å–æ•°æ®å•å…ƒå®žä¾‹
        
        Args:
            unit_name: æ•°æ®å•å…ƒåç§°
            
        Returns:
            æ•°æ®å•å…ƒå®žä¾‹
        """
        return self.data_unit_manager.get_data_unit(unit_name)

    # ==================== File System Registration ====================
        def registerFileSystem(self, file_system_cls):
        """æ³¨å†Œæ–‡ä»¶ç³»ç»Ÿå®žä¾‹ï¼Œæ–¹ä¾¿é›†ä¸­ç®¡ç†
        
        Args:
            file_system_cls: æ–‡ä»¶ç³»ç»Ÿç±»
        """
        return self.file_system_manager.register_file_system(file_system_cls)

    def getFileSystem(self):
        """èŽ·å–æ–‡ä»¶ç³»ç»Ÿå®žä¾‹
        
        Returns:
            æ–‡ä»¶ç³»ç»Ÿå®žä¾‹
        """
        return self.file_system_manager.get_file_system()

    # ==================== Communicator Registration ====================
    def registerCommunicator(self, communicator_cls):
        """æ³¨å†Œé€šä¿¡å™¨å®žä¾‹ï¼Œæ–¹ä¾¿é›†ä¸­ç®¡ç†

        Args:
            communicator_cls: é€šä¿¡å™¨ç±»
        """

        def wrapper(*args, **kwargs):
            """æ³¨å†Œé€šä¿¡å™¨å®žä¾‹"""
            if self.communicator_ is not None:
                logger.error("currently do not support multiple communicators!")
                raise ValueError("communicator already exists!")

            self.communicator_ = communicator_cls(*args, **kwargs)

            comm_name = getattr(self.communicator_, "name", "Unknown")
            logger.info(f"Successfully registered communicator: {comm_name}")

            return self.communicator_

        return wrapper

    def getCommunicator(self):
        """èŽ·å–é€šä¿¡å™¨å®žä¾‹

        Returns:
            é€šä¿¡å™¨å®žä¾‹
        """
        if self.communicator_ is None:
            logger.error("Communicator not exists!")
            raise ValueError("Communicator not exists!")

        return self.communicator_

    # ==================== Runner Registration ====================
    def registerRunner(self, runner_name: str):
        """æ³¨å†Œrunneråç§°ï¼Œç”¨äºŽè®°å½•å½“å‰è¿è¡Œçš„runneråç§°

        Args:
            runner_name: runneråç§°
        """
        self.runner_name_ = runner_name

        if self.file_system_ is None:
            logger.warning("file system not exists!")
            logger.warning("do not forget to configure runner in file system!")
        else:
            self.file_system_.configRunner(runner_name)
            logger.info(f"Successfully registered runner: {runner_name}")

    def getRunner(self) -> str:
        """èŽ·å–runneråç§°

        Returns:
            runneråç§°
        """
        if self.runner_name_ is None:
            logger.error("Runner not exists!")
            raise ValueError("Runner not exists!")

        return self.runner_name_

    # ==================== Data Manager Registration ====================
    def register_data_manager(self, data_manager_cls):
        """æ³¨å†Œæ•°æ®ç®¡ç†å™¨ç±»

        Args:
            data_manager_cls: æ•°æ®ç®¡ç†å™¨ç±»

        Returns:
            Wrapper function
        """

        def wrapper(*args, **kwargs):
            data_manager_instance = data_manager_cls(*args, **kwargs)
            self._data_manager = data_manager_instance
            logger.info("Successfully registered data manager")
            return data_manager_instance

        return wrapper

    def get_data_manager(self):
        """èŽ·å–æ³¨å†Œçš„æ•°æ®ç®¡ç†å™¨"""
        if self._data_manager is None:
            logger.error("Data manager not exists!")
            raise ValueError("Data manager not exists!")
        return self._data_manager

    # ==================== Data Management ====================
    def saveDataUnitInfo(self):
        """ä¿å­˜æ•°æ®å•å…ƒä¿¡æ¯"""
        if self.runner_name_ is None:
            logger.error("runner name not exists!")
            raise ValueError("runner name not exists!")

        save_dict = {}

        # å°†æ•°æ®å•å…ƒçš„çŠ¶æ€ä¿å­˜åˆ°å­—å…¸ä¸­
        for key, value in self.data_units_.items():
            try:
                save_dict[key] = value.getUnitStatusDict()
            except AttributeError:
                logger.warning(
                    f"Data unit {key} does not have getUnitStatusDict method"
                )
                save_dict[key] = {}

        # ä¿å­˜æ•°æ®å•å…ƒåˆ°æ–‡ä»¶ç³»ç»Ÿä¸­
        if self.file_system_ is not None:
            self.file_system_.saveDataUnit(
                runner_name=self.runner_name_, data_unit_status=save_dict
            )
            logger.info(f"Saved data unit info for {len(save_dict)} units")
        else:
            logger.warning("File system not available, cannot save data unit info")

    # ==================== Plugin and Config Management ====================
    def get_plugin_manager(self):
        """èŽ·å–æ’ä»¶ç®¡ç†å™¨"""
        return self._plugin_manager

    def get_config_manager(self):
        """èŽ·å–é…ç½®ç®¡ç†å™¨"""
        return self._config_manager

    # ==================== Utility Methods ====================
    def list_components(self) -> Dict[str, int]:
        """åˆ—å‡ºæ‰€æœ‰å·²æ³¨å†Œçš„ç»„ä»¶

        Returns:
            ç»„ä»¶ç±»åž‹åŠæ•°é‡çš„å­—å…¸
        """
        components = {
            "models": len(self.models_dict_),
            "data_units": len(self.data_units_),
            "environment": 1 if self.env_ is not None else 0,
            "agent": 1 if self.agent_ is not None else 0,
            "file_system": 1 if self.file_system_ is not None else 0,
            "communicator": 1 if self.communicator_ is not None else 0,
            "data_manager": 1 if self._data_manager is not None else 0,
            "runner": 1 if self.runner_name_ is not None else 0,
        }
        return components

    def get_status(self) -> Dict[str, Any]:
        """èŽ·å–åè°ƒå™¨çŠ¶æ€

        Returns:
            çŠ¶æ€å­—å…¸
        """
        return {
            "initialized": self._initialized,
            "components": self.list_components(),
            "device_info": self.get_device_info(),
            "runner_name": self.runner_name_,
        }

    def shutdown(self) -> None:
        """å…³é—­åè°ƒå™¨"""
        try:
            # æ¸…ç©ºæ‰€æœ‰ç»„ä»¶å¼•ç”¨
            self.models_dict_.clear()
            self.data_units_.clear()
            self.env_ = None
            self.agent_ = None
            self.file_system_ = None
            self.communicator_ = None
            self._data_manager = None
            self.runner_name_ = None

            logger.info("AquaML Coordinator shutdown completed")

        except Exception as e:
            logger.error(f"Error during coordinator shutdown: {e}")

    def __enter__(self):
        """Context manager entry"""
        return self

    def __exit__(self, exc_type, exc_val, exc_tb):
        """Context manager exit"""
        self.shutdown()


# Global coordinator instance
coordinator = AquaMLCoordinator()


def get_coordinator() -> AquaMLCoordinator:
    """Get the global coordinator instance"""
    return coordinator
