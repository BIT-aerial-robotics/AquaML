from typing import TYPE_CHECKING
from AquaML import coordinator
import abc

if TYPE_CHECKING:
    from AquaML.rl_algo import BaseRLAgent
    from AquaML.env.base_env import BaseEnv


class BaseWorker(abc.ABC):
    '''
    Base class for all workers.

    '''

    def __init__(self):
        '''
        Initialize the worker.

        '''
        self.env_ = coordinator.getEnv()  # The environment.
        self.agent_ = coordinator.getAgent()  # The agent.

    def step(self, action: dict) -> tuple:
        '''
        Interact with the environment,the action is generated by the agent.
        Then return the next state, reward, done, and info.
        Last, get all the information and store them in the replay buffer.

        Each data shape is regulated as follows,
        >>> (num_machines, num_envs, feature_dim)

        :param action: The action to take.
        :type action: dict{str: tensor or numpy.array} or tensor or numpy.array.

        :return: The next state, reward, done, and info.
        :rtype: dict{str: tensor or numpy.array}, tensor or numpy.array, tensor or numpy.array, dict{str: tensor or numpy.array}.
        '''

        env = self.getEnv()

        next_state, reward, done, truncated, info = env.step(action)

        return next_state, reward, done, truncated, info

    @abc.abstractmethod
    def run(self):
        '''
        Run the worker, get the state from the environment, and input it to the agent to get the action.

        Then store the state, action, reward, next_state, done, and truncated in the transfer data unit.
        Last, replay buffer get the data from the transfer data unit.

        We also support directly store the data in the replay buffer.

        When using multi-process, we recommend using the method one.
        When using single process, we recommend using the method two.
        '''
