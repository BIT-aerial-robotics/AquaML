# AquaML 模块文档

## 项目概述

AquaML 是一个专注于强化学习和现实世界机器人应用的综合性进化机器学习框架。该框架提供了模块化架构，支持在线和离线学习、多进程通信以及与各种机器人API的集成。

## 项目结构

```
AquaML/
├── framework/          # 核心框架实现
├── param/             # 参数定义和数据结构
├── policy/            # 策略实现
├── core/              # 核心工具和基础类
├── communicator/      # 多进程通信
├── tf/                # TensorFlow实现
├── torch/             # PyTorch实现（如果可用）
├── RobotAPI/          # 机器人接口实现
├── buffer/            # 数据缓冲区实现
├── algo/              # 算法基础类
├── algo_base/         # 算法基础抽象
├── worker/            # 分布式训练工作进程
├── recorder/          # 数据记录和日志
├── config/            # 配置文件
└── Tool/              # 实用工具
```

## 模块详细文档

### 1. 框架模块 (`framework/`)

**用途**: 包含进化机器学习的核心框架实现。

**关键组件**:
- **`EvolutionML.py`**: 协调整个系统的主要框架类
  - 管理现实世界策略、策略更新器、机器人API和策略选择器
  - 处理多进程通信和协调
  - 支持在线和离线学习模式
  - 管理不同系统组件之间的数据流

- **`RL.py`**: 强化学习框架基础
- **`FrameWorkBase.py`**: 所有框架实现的基础类
- **`RealUpdaterStarter.py`**: 管理现实世界策略更新
- **`Offline2online.py`**: 处理从离线到在线学习的转换

**主要特性**:
- 不同学习算法的统一接口
- 多进程任务协调
- 现实世界机器人交互管理
- 策略候选选择和评估

### 2. 参数模块 (`param/`)

**用途**: 定义整个系统的参数结构和数据信息。

**关键组件**:
- **`DataInfo.py`**: 核心数据结构管理
  - 定义环境信息和数据模式
  - 管理强化学习状态、动作和奖励
  - 处理数据元素注册和验证

- **`AquaParam.py`**: 通用参数定义
- **`OfflineRL.py`**: 离线强化学习特定参数
- **`PolicyCandidate.py`**: 策略候选参数
- **`Buffer.py`**: 缓冲区配置参数
- **`ParamBase.py`**: 基础参数类

**主要特性**:
- 类型安全的参数定义
- 验证和模式管理
- 分层参数组织

### 3. 策略模块 (`policy/`)

**用途**: 实现不同用例的各种策略类型。

**关键组件**:
- **`RealWorldPolicy.py`**: 现实世界交互策略
  - `DeterminateRealWorldPolicy`: 用于现实世界部署的确定性策略
  - 支持模型切换和权重加载
  - 连续交互的线程安全操作

- **`FixNNPolicy.py`**: 固定神经网络策略
- **`PolicyBase.py`**: 所有策略的基础类
- **`RealWorldPolicyBase.py`**: 现实世界策略的基础类

**主要特性**:
- 实时策略执行
- 模型切换能力
- 多线程策略管理
- 与文件系统集成进行模型更新

### 4. 核心模块 (`core/`)

**用途**: 提供整个系统中使用的核心工具和基础类。

**关键组件**:
- **`DataModule.py`**: 数据管理和处理
- **`DataUnit.py`**: 基本数据单元定义
- **`Tool.py`**: 工具函数和实用工具
- **`FileSystem.py`**: 文件系统操作
- **`DataInfo.py`**: 数据信息管理
- **`DataList.py`**: 数据列表操作
- **`Communicator.py`**: 通信协议
- **`Recorder.py`**: 数据记录工具
- **`Protocol.py`**: 系统协议
- **`TaskBase.py`**: 任务基础定义

**主要特性**:
- 数据结构管理
- 文件I/O操作
- 系统工具
- 协议定义

### 5. 通信模块 (`communicator/`)

**用途**: 处理多进程通信和协调。

**关键组件**:
- **`MPICommunicator.py`**: 基于MPI的通信
  - 使用MPI进行分布式处理
  - 支持进程同步和屏障
  - 可配置的日志和调试

- **`DebugCommunicator.py`**: 用于测试的仅调试通信
- **`CommunicatorBase.py`**: 基础通信类
- **`ProcessSimulator.py`**: 进程模拟工具

**主要特性**:
- 分布式计算支持
- 进程同步
- 日志和调试
- 可扩展的通信模式

### 6. TensorFlow模块 (`tf/`)

**用途**: 算法和模型的TensorFlow特定实现。

**关键组件**:

#### 6.1 离线强化学习 (`tf/OfflineRL/`)
- **`IQL.py`**: 隐式Q学习实现
  - 带有状态值函数的Actor-Critic架构
  - 保守学习的期望回归
  - 支持连续动作空间

- **`TD3BC.py`**: 带行为克隆的双延迟深度确定性策略梯度
  - 结合TD3与行为克隆
  - 保守更新的离线强化学习

#### 6.2 策略候选 (`tf/PolicyCandidate/`)
- **`PEX.py`**: 策略扩展（PEX）实现
  - 策略候选选择算法
  - 支持IQL和TD3BC后端
  - 基于温度的策略选择

#### 6.3 通用组件
- **`TFAlgoBase.py`**: TensorFlow算法基础类
- **`Dataset.py`**: TensorFlow数据集管理

**主要特性**:
- 最先进的离线强化学习算法
- 策略候选评估
- TensorFlow集成
- GPU支持

### 7. 机器人API模块 (`RobotAPI/`)

**用途**: 为不同的机器人平台和模拟器提供接口。

**关键组件**:
- **`GymWrapper.py`**: OpenAI Gym环境包装器
  - Gym环境的标准化接口
  - 支持各种观测和动作空间
  - 回合管理和重置功能

- **`GymWrapperPex.py`**: 带PEX集成的Gym包装器
- **`ROSAPI.py`**: ROS（机器人操作系统）集成
- **`APIBase.py`**: 所有机器人API的基础类
- **`ROSExample.py`**: ROS实现示例

**主要特性**:
- 多平台机器人支持
- 标准化API接口
- 实时机器人控制
- 仿真环境集成

### 8. 缓冲区模块 (`buffer/`)

**用途**: 实现各种数据缓冲区类型，用于经验回放和数据管理。

**关键组件**:
- **`BufferBase.py`**: 基础缓冲区实现
- **`MixtureBuffer.py`**: 不同数据类型的混合数据缓冲区
- **`MixtureBufferBase.py`**: 混合缓冲区基础类
- **`RealCollectBuffer.py`**: 现实世界数据收集缓冲区
- **`RealCollectBufferBase.py`**: 实际收集缓冲区基础类
- **`DynamicBufferBase.py`**: 可变大小的动态缓冲区

**主要特性**:
- 高效的数据存储和检索
- 针对不同用例的多种缓冲区类型
- 内存管理
- 实时数据收集支持

### 9. 算法模块 (`algo/`)

**用途**: 学习算法的基础类和接口。

**关键组件**:
- **`AlgoBase.py`**: 基础算法类
- **`RLAlgoBase.py`**: 强化学习算法基础类
- **`ModelBase.py`**: 基础模型类

**主要特性**:
- 算法抽象
- 一致的接口设计
- 可扩展的架构

### 10. 算法基础模块 (`algo_base/`)

**用途**: 为不同算法类别提供抽象基础类。

**关键组件**:
- **`OfflineRLBase.py`**: 离线强化学习算法基础类
- 其他算法基础类

**主要特性**:
- 类型安全的算法接口
- 通用功能抽象
- 一致的API设计

### 11. 工作进程模块 (`worker/`)

**用途**: 实现分布式训练和数据收集的工作进程。

**关键组件**:
- **`RLWorker.py`**: 标准强化学习工作进程
- **`RLWorkerBase.py`**: 基础强化学习工作进程类
- **`RLCollector.py`**: 数据收集工作进程
- **`RLVectorEnv.py`**: 向量化环境工作进程
- **`RLEnvBase.py`**: 环境基础类
- **`RLIsaacGymWorker.py`**: Isaac Gym特定工作进程
- **`RLAerialGymWorker.py`**: Aerial Gym特定工作进程

**主要特性**:
- 分布式训练支持
- 并行数据收集
- 环境向量化
- 平台特定优化

### 12. 记录模块 (`recorder/`)

**用途**: 处理数据记录、日志和实验跟踪。

**关键组件**:
- **`RecorderBase.py`**: 基础记录器类
- **`WandbRecorder.py`**: Weights & Biases集成
- **`BoardRecorder.py`**: TensorBoard集成

**主要特性**:
- 实验跟踪
- 指标可视化
- 多后端支持
- 实时监控

### 13. 配置模块 (`config/`)

**用途**: 包含框架的配置文件和设置。

**主要特性**:
- 进程配置
- 环境设置
- 算法参数
- 系统配置

### 14. 工具模块 (`Tool/`)

**用途**: 实用工具和辅助函数。

**主要特性**:
- 数据处理工具
- 可视化工具
- 系统工具
- 开发辅助工具

## 使用示例

该框架的使用方式如`IQLBipedalWalker.py`示例所示：

1. **定义环境**: 使用`DataInfo`设置环境信息
2. **配置通信**: 使用`MPICommunicator`设置多进程通信
3. **定义网络**: 创建actor和critic的神经网络架构
4. **配置算法**: 设置离线强化学习算法（如IQL）
5. **定义策略**: 配置机器人交互的现实世界策略
6. **设置机器人API**: 配置机器人接口（如Gym环境）
7. **初始化框架**: 使用所有组件创建`EvolutionML`实例
8. **运行训练**: 执行训练循环

## 关键设计原则

1. **模块化**: 每个组件都设计为独立且可替换
2. **可扩展性**: 易于添加新算法、策略和机器人平台
3. **可扩展性**: 支持分布式训练和多进程执行
4. **现实世界导向**: 专门为现实世界机器人应用设计
5. **框架无关**: 支持TensorFlow和PyTorch（计划中）

## 依赖项

- TensorFlow 2.x
- OpenAI Gym
- MPI4Py（用于分布式计算）
- NumPy
- Weights & Biases（可选，用于实验跟踪）
- ROS（可选，用于机器人集成）

## 注意事项

- 框架正在积极开发中，一些模块标记为"old"表示正在重构
- TensorFlow实现可用GPU支持
- 系统支持仿真和现实世界机器人部署
- 多进程通信支持分布式系统上的可扩展训练 