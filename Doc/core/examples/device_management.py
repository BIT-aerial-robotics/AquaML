#!/usr/bin/env python3
"""
AquaML Core - è®¾å¤‡ç®¡ç†ç¤ºä¾‹

æœ¬ç¤ºä¾‹å±•ç¤ºäº†AquaMLæ¡†æ¶çš„è®¾å¤‡ç®¡ç†åŠŸèƒ½ï¼ŒåŒ…æ‹¬ï¼š
- è®¾å¤‡æ£€æµ‹å’Œé€‰æ‹©
- è®¾å¤‡éªŒè¯
- è®¾å¤‡ä¿¡æ¯æŸ¥è¯¢
- è®¾å¤‡åˆ‡æ¢
- ä¸PyTorché›†æˆ
"""

import torch
import torch.nn as nn
from AquaML.core import AquaMLCoordinator


def demonstrate_device_detection():
    """æ¼”ç¤ºè®¾å¤‡æ£€æµ‹åŠŸèƒ½"""
    print("=== è®¾å¤‡æ£€æµ‹ ===")
    
    coordinator = AquaMLCoordinator()
    
    # è·å–è®¾å¤‡ä¿¡æ¯
    device_info = coordinator.get_device_info()
    print(f"å½“å‰è®¾å¤‡: {device_info['current_device']}")
    print(f"å¯ç”¨è®¾å¤‡: {device_info['available_devices']}")
    print(f"GPUå¯ç”¨: {device_info['gpu_available']}")
    print(f"GPUæ•°é‡: {device_info['gpu_count']}")
    
    if device_info['gpu_available']:
        print("GPUè¯¦ç»†ä¿¡æ¯:")
        for i, gpu_info in enumerate(device_info['gpu_details']):
            print(f"  GPU {i}: {gpu_info}")
    
    print()


def demonstrate_device_selection():
    """æ¼”ç¤ºè®¾å¤‡é€‰æ‹©åŠŸèƒ½"""
    print("=== è®¾å¤‡é€‰æ‹© ===")
    
    coordinator = AquaMLCoordinator()
    
    # æ£€æŸ¥GPUæ˜¯å¦å¯ç”¨
    if coordinator.is_gpu_available():
        print("æ£€æµ‹åˆ°GPUï¼Œå°è¯•ä½¿ç”¨GPU")
        if coordinator.set_device("cuda:0"):
            print("âœ“ æˆåŠŸè®¾ç½®ä¸ºGPU 0")
        else:
            print("âœ— è®¾ç½®GPUå¤±è´¥ï¼Œå›é€€åˆ°CPU")
            coordinator.set_device("cpu")
    else:
        print("æœªæ£€æµ‹åˆ°GPUï¼Œä½¿ç”¨CPU")
        coordinator.set_device("cpu")
    
    print(f"æœ€ç»ˆé€‰æ‹©çš„è®¾å¤‡: {coordinator.get_device()}")
    print()


def demonstrate_device_validation():
    """æ¼”ç¤ºè®¾å¤‡éªŒè¯åŠŸèƒ½"""
    print("=== è®¾å¤‡éªŒè¯ ===")
    
    coordinator = AquaMLCoordinator()
    
    # æµ‹è¯•ä¸åŒè®¾å¤‡çš„éªŒè¯
    test_devices = ["cpu", "cuda:0", "cuda:1", "cuda:99"]
    
    for device in test_devices:
        is_valid = coordinator.validate_device(device)
        status = "âœ“ å¯ç”¨" if is_valid else "âœ— ä¸å¯ç”¨"
        print(f"è®¾å¤‡ {device}: {status}")
    
    print()


def demonstrate_device_switching():
    """æ¼”ç¤ºè®¾å¤‡åˆ‡æ¢åŠŸèƒ½"""
    print("=== è®¾å¤‡åˆ‡æ¢ ===")
    
    coordinator = AquaMLCoordinator()
    
    # è·å–å¯ç”¨è®¾å¤‡åˆ—è¡¨
    available_devices = coordinator.get_available_devices()
    print(f"å¯ç”¨è®¾å¤‡: {available_devices}")
    
    # ä¾æ¬¡åˆ‡æ¢åˆ°æ¯ä¸ªå¯ç”¨è®¾å¤‡
    for device in available_devices:
        if coordinator.set_device(device):
            print(f"âœ“ æˆåŠŸåˆ‡æ¢åˆ° {device}")
        else:
            print(f"âœ— åˆ‡æ¢åˆ° {device} å¤±è´¥")
    
    print()


def demonstrate_pytorch_integration():
    """æ¼”ç¤ºä¸PyTorchçš„é›†æˆ"""
    print("=== PyTorché›†æˆ ===")
    
    coordinator = AquaMLCoordinator()
    
    # è‡ªåŠ¨é€‰æ‹©æœ€ä½³è®¾å¤‡
    if coordinator.is_gpu_available():
        coordinator.set_device("cuda:0")
    else:
        coordinator.set_device("cpu")
    
    # è·å–PyTorchè®¾å¤‡å¯¹è±¡
    torch_device = coordinator.get_torch_device()
    print(f"PyTorchè®¾å¤‡: {torch_device}")
    
    # åˆ›å»ºä¸€ä¸ªç®€å•çš„æ¨¡å‹
    class SimpleModel(nn.Module):
        def __init__(self):
            super().__init__()
            self.linear = nn.Linear(10, 1)
        
        def forward(self, x):
            return self.linear(x)
    
    # åˆ›å»ºæ¨¡å‹å¹¶ç§»åŠ¨åˆ°æŒ‡å®šè®¾å¤‡
    model = SimpleModel()
    model.to(torch_device)
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    x = torch.randn(5, 10).to(torch_device)
    
    # å‰å‘ä¼ æ’­
    with torch.no_grad():
        output = model(x)
    
    print(f"æ¨¡å‹è®¾å¤‡: {next(model.parameters()).device}")
    print(f"è¾“å…¥æ•°æ®è®¾å¤‡: {x.device}")
    print(f"è¾“å‡ºæ•°æ®è®¾å¤‡: {output.device}")
    print(f"è¾“å‡ºå½¢çŠ¶: {output.shape}")
    
    print()


def demonstrate_robust_device_handling():
    """æ¼”ç¤ºé²æ£’çš„è®¾å¤‡å¤„ç†"""
    print("=== é²æ£’è®¾å¤‡å¤„ç† ===")
    
    coordinator = AquaMLCoordinator()
    
    # å®šä¹‰é¦–é€‰è®¾å¤‡åˆ—è¡¨ï¼ˆæŒ‰ä¼˜å…ˆçº§æ’åºï¼‰
    preferred_devices = ["cuda:0", "cuda:1", "cpu"]
    
    selected_device = None
    for device in preferred_devices:
        if coordinator.validate_device(device):
            if coordinator.set_device(device):
                selected_device = device
                print(f"âœ“ æˆåŠŸé€‰æ‹©è®¾å¤‡: {device}")
                break
            else:
                print(f"âœ— è®¾å¤‡ {device} éªŒè¯æˆåŠŸä½†è®¾ç½®å¤±è´¥")
        else:
            print(f"âœ— è®¾å¤‡ {device} ä¸å¯ç”¨")
    
    if selected_device:
        print(f"æœ€ç»ˆä½¿ç”¨è®¾å¤‡: {selected_device}")
    else:
        print("é”™è¯¯: æ— æ³•é€‰æ‹©ä»»ä½•è®¾å¤‡")
    
    print()


def demonstrate_config_based_device_selection():
    """æ¼”ç¤ºåŸºäºé…ç½®çš„è®¾å¤‡é€‰æ‹©"""
    print("=== é…ç½®é©±åŠ¨çš„è®¾å¤‡é€‰æ‹© ===")
    
    # æ¨¡æ‹Ÿä¸åŒçš„é…ç½®åœºæ™¯
    configs = [
        {"device": "cuda:0", "name": "GPUä¼˜å…ˆé…ç½®"},
        {"device": "cpu", "name": "CPUå¼ºåˆ¶é…ç½®"},
        {"device": "cuda:99", "name": "æ— æ•ˆGPUé…ç½®"},
        {}, # æ— è®¾å¤‡é…ç½®ï¼Œä½¿ç”¨è‡ªåŠ¨é€‰æ‹©
    ]
    
    for i, config in enumerate(configs):
        print(f"é…ç½® {i+1}: {config.get('name', 'è‡ªåŠ¨é€‰æ‹©é…ç½®')}")
        
        coordinator = AquaMLCoordinator()
        coordinator.initialize(config)
        
        device = coordinator.get_device()
        is_valid = coordinator.validate_device(device)
        
        print(f"  é€‰æ‹©çš„è®¾å¤‡: {device}")
        print(f"  è®¾å¤‡æœ‰æ•ˆæ€§: {'âœ“' if is_valid else 'âœ—'}")
        print()


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸŒŠ AquaML Core - è®¾å¤‡ç®¡ç†ç¤ºä¾‹ ğŸŒŠ")
    print("=" * 50)
    
    try:
        demonstrate_device_detection()
        demonstrate_device_selection()
        demonstrate_device_validation()
        demonstrate_device_switching()
        demonstrate_pytorch_integration()
        demonstrate_robust_device_handling()
        demonstrate_config_based_device_selection()
        
        print("âœ… æ‰€æœ‰ç¤ºä¾‹è¿è¡Œå®Œæˆï¼")
        
    except Exception as e:
        print(f"âŒ è¿è¡Œç¤ºä¾‹æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main() 