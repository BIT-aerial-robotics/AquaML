#!/usr/bin/env python3
"""
AquaML Manager System Demo

This script demonstrates the usage of the new AquaML manager system architecture.
"""

import torch
import torch.nn as nn
from AquaML.core.coordinator import get_coordinator


def main():
    """æ¼”ç¤ºAquaMLç®¡ç†å™¨ç³»ç»Ÿçš„ä½¿ç”¨"""
    print("ğŸŒŠ AquaML Manager System Demo ğŸŒŠ")
    print("=" * 50)

    # è·å–åè°ƒå™¨å®ä¾‹
    coordinator = get_coordinator()

    print("\n1. ğŸ“‹ åˆå§‹çŠ¶æ€")
    print("-" * 30)
    initial_status = coordinator.get_status()
    print(f"åˆå§‹åŒ–çŠ¶æ€: {initial_status['initialized']}")
    print(f"ç»„ä»¶æ•°é‡: {initial_status['components']}")

    print("\n2. ğŸ¤– æ³¨å†Œæ¨¡å‹")
    print("-" * 30)

    class PolicyNetwork(nn.Module):
        def __init__(self):
            super().__init__()
            self.layers = nn.Sequential(
                nn.Linear(64, 128),
                nn.ReLU(),
                nn.Linear(128, 64),
                nn.ReLU(),
                nn.Linear(64, 4),
            )

        def forward(self, x):
            return self.layers(x)

    class ValueNetwork(nn.Module):
        def __init__(self):
            super().__init__()
            self.layers = nn.Sequential(
                nn.Linear(64, 128), nn.ReLU(), nn.Linear(128, 1)
            )

        def forward(self, x):
            return self.layers(x)

    # æ³¨å†Œæ¨¡å‹
    policy_net = PolicyNetwork()
    value_net = ValueNetwork()

    coordinator.registerModel(policy_net, "policy_network")
    coordinator.registerModel(value_net, "value_network")

    # è·å–æ¨¡å‹ç®¡ç†å™¨å¹¶æ˜¾ç¤ºçŠ¶æ€
    model_manager = coordinator.get_model_manager()
    print(f"âœ… å·²æ³¨å†Œæ¨¡å‹: {model_manager.list_models()}")
    print(f"âœ… æ¨¡å‹æ•°é‡: {model_manager.get_models_count()}")

    print("\n3. ğŸƒ æ³¨å†ŒRunner")
    print("-" * 30)

    coordinator.registerRunner("demo_runner_v1.0")
    runner_manager = coordinator.get_runner_manager()
    print(f"âœ… è¿è¡Œå™¨: {runner_manager.get_runner()}")

    print("\n4. ğŸŒ æ³¨å†Œç¯å¢ƒ")
    print("-" * 30)

    @coordinator.registerEnv
    class DemoEnvironment:
        def __init__(self):
            self.name = "DemoEnv"
            self.state_dim = 64
            self.action_dim = 4
            self.current_step = 0

        def reset(self):
            self.current_step = 0
            return torch.randn(self.state_dim)

        def step(self, action):
            self.current_step += 1
            next_state = torch.randn(self.state_dim)
            reward = torch.randn(1).item()
            done = self.current_step >= 100
            return next_state, reward, done, {}

    env = DemoEnvironment()
    env_manager = coordinator.get_environment_manager()
    print(f"âœ… ç¯å¢ƒ: {env.name}")
    print(f"âœ… çŠ¶æ€ç»´åº¦: {env.state_dim}, åŠ¨ä½œç»´åº¦: {env.action_dim}")

    print("\n5. ğŸ¤– æ³¨å†ŒAgent")
    print("-" * 30)

    @coordinator.registerAgent
    class DemoAgent:
        def __init__(self):
            self.name = "DemoAgent"
            self.episode_count = 0

        def act(self, state):
            # ç®€å•çš„éšæœºç­–ç•¥
            return torch.randint(0, 4, (1,)).item()

        def update(self, experience):
            # æ¨¡æ‹Ÿå­¦ä¹ è¿‡ç¨‹
            pass

        def new_episode(self):
            self.episode_count += 1

    agent = DemoAgent()
    agent_manager = coordinator.get_agent_manager()
    print(f"âœ… æ™ºèƒ½ä½“: {agent.name}")

    print("\n6. ğŸ“Š æ³¨å†Œæ•°æ®å•å…ƒ")
    print("-" * 30)

    @coordinator.registerDataUnit
    class ExperienceBuffer:
        def __init__(self):
            self.name = "ExperienceBuffer"
            self.experiences = []
            self.max_size = 10000

        def add_experience(self, state, action, reward, next_state, done):
            experience = {
                "state": state,
                "action": action,
                "reward": reward,
                "next_state": next_state,
                "done": done,
            }
            self.experiences.append(experience)
            if len(self.experiences) > self.max_size:
                self.experiences.pop(0)

        def sample_batch(self, batch_size=32):
            import random

            return random.sample(
                self.experiences, min(batch_size, len(self.experiences))
            )

        def getUnitStatusDict(self):
            return {
                "size": len(self.experiences),
                "max_size": self.max_size,
                "status": "active",
            }

    buffer = ExperienceBuffer()
    data_unit_manager = coordinator.get_data_unit_manager()
    print(f"âœ… æ•°æ®å•å…ƒ: {buffer.name}")

    print("\n7. ğŸ¯ è¿è¡Œç®€å•çš„äº¤äº’å¾ªç¯")
    print("-" * 30)

    # è¿è¡Œå‡ ä¸ªæ­¥éª¤æ¥æ¼”ç¤ºç³»ç»Ÿäº¤äº’
    env = coordinator.getEnv()
    agent = coordinator.getAgent()
    buffer = coordinator.getDataUnit("ExperienceBuffer")

    state = env.reset()
    total_reward = 0

    for step in range(5):
        action = agent.act(state)
        next_state, reward, done, _ = env.step(action)

        # å­˜å‚¨ç»éªŒ
        buffer.add_experience(state, action, reward, next_state, done)

        total_reward += reward
        state = next_state

        print(f"æ­¥éª¤ {step + 1}: åŠ¨ä½œ={action}, å¥–åŠ±={reward:.3f}")

        if done:
            break

    print(f"âœ… æ€»å¥–åŠ±: {total_reward:.3f}")
    print(f"âœ… ç»éªŒç¼“å†²åŒºå¤§å°: {len(buffer.experiences)}")

    print("\n8. ğŸ“ˆ ç³»ç»ŸçŠ¶æ€æ€»è§ˆ")
    print("-" * 30)

    # æ˜¾ç¤ºæ‰€æœ‰ç®¡ç†å™¨çš„çŠ¶æ€
    all_status = coordinator.get_all_managers_status()
    for manager_name, status in all_status.items():
        print(f"ğŸ“Š {manager_name}: {status}")

    print("\n9. ğŸ”§ ç®¡ç†å™¨ç›´æ¥è®¿é—®ç¤ºä¾‹")
    print("-" * 30)

    # å±•ç¤ºå¦‚ä½•ç›´æ¥è®¿é—®ç®¡ç†å™¨è¿›è¡Œæ›´ç²¾ç»†çš„æ§åˆ¶
    model_manager = coordinator.get_model_manager()

    # æ£€æŸ¥ç‰¹å®šæ¨¡å‹æ˜¯å¦å­˜åœ¨
    if model_manager.model_exists("policy_network"):
        policy_model = model_manager.get_model_instance("policy_network")
        print(
            f"âœ… ç­–ç•¥ç½‘ç»œå‚æ•°æ•°é‡: {sum(p.numel() for p in policy_model.parameters())}"
        )

    # æ˜¾ç¤ºæ¨¡å‹è¯¦ç»†ä¿¡æ¯
    for model_name in model_manager.list_models():
        model_dict = model_manager.get_model(model_name)
        model_instance = model_dict["model"]
        print(f"âœ… æ¨¡å‹ '{model_name}': {type(model_instance).__name__}")

    print("\n10. ğŸ’¾ æ•°æ®æŒä¹…åŒ–æ¼”ç¤º")
    print("-" * 30)

    # æ³¨å†Œä¸€ä¸ªç®€å•çš„æ–‡ä»¶ç³»ç»Ÿ
    @coordinator.registerFileSystem
    class DemoFileSystem:
        def __init__(self):
            self.saved_data = {}
            self.configured_runners = []

        def configRunner(self, runner_name):
            self.configured_runners.append(runner_name)
            print(f"âœ… é…ç½®è¿è¡Œå™¨: {runner_name}")

        def saveDataUnit(self, runner_name, data_unit_status):
            self.saved_data[runner_name] = data_unit_status
            print(f"âœ… ä¿å­˜æ•°æ®å•å…ƒçŠ¶æ€: {runner_name}")

    fs = DemoFileSystem()

    # ä¿å­˜æ•°æ®å•å…ƒä¿¡æ¯
    coordinator.saveDataUnitInfo()

    print("\n11. ğŸ“‹ æœ€ç»ˆçŠ¶æ€æŠ¥å‘Š")
    print("-" * 30)

    final_status = coordinator.get_status()
    print(f"ğŸ¯ æœ€ç»ˆçŠ¶æ€:")
    print(f"   - åˆå§‹åŒ–: {final_status['initialized']}")
    print(f"   - ç»„ä»¶: {final_status['components']}")
    print(f"   - è®¾å¤‡ä¿¡æ¯: {final_status['device_info']['current_device']}")
    print(f"   - è¿è¡Œå™¨: {final_status['runner_name']}")

    print("\nğŸ‰ æ¼”ç¤ºå®Œæˆï¼æ–°çš„ç®¡ç†å™¨ç³»ç»Ÿè¿è¡Œæ­£å¸¸ã€‚")
    print("\nğŸ’¡ æç¤º:")
    print("   - æ¯ä¸ªç»„ä»¶éƒ½æœ‰ä¸“é—¨çš„ç®¡ç†å™¨è´Ÿè´£ç®¡ç†")
    print("   - å¯ä»¥é€šè¿‡åè°ƒå™¨ç»Ÿä¸€è®¿é—®ï¼Œä¹Ÿå¯ä»¥ç›´æ¥è®¿é—®ç®¡ç†å™¨")
    print("   - å®Œæ•´çš„é”™è¯¯å¤„ç†å’ŒçŠ¶æ€ç®¡ç†")
    print("   - æ˜“äºæ‰©å±•å’Œæµ‹è¯•")


if __name__ == "__main__":
    main()
